{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 1)\n",
      "(2, 2, 1, 1)\n",
      "(1, 2, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "#Convolution example\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#image형태\n",
    "#1장의 이미지는 3차원형태의 데이터\n",
    "#(이미지의 개수, width, height, color)\n",
    "#(1,3,3,1)\n",
    "image = np.array([[[[1],[2],[3]],\n",
    "                  [[4],[5],[6]],\n",
    "                  [[7],[8],[9]]]], dtype=np.float32)  #(list안에 list넣어서 4차원의 np.array만들기)\n",
    "print(image.shape)\n",
    "#필터를 준비해야해요\n",
    "#(Width, height, color, 필터의 개수)\n",
    "#(2,2,1,1)\n",
    "\n",
    "weight = np.array([[[[1]],[[1]]],\n",
    "                   [[[1]],[[1]]]])\n",
    "\n",
    "print(weight.shape)\n",
    "#원본이미지 만들었고, 필터 만들었어요 => mapping시켜요!\n",
    "#mapping을 얼마의 간격으로 할건지도 정해요 - stride\n",
    "#stride지정(사실 2차원이면 되는데 행렬곱 연산을 위해서 어쩔수 없이 4차원으로 만들어줘야한다. (2개는 사용되지 않음)\n",
    "##(1, stride width, stride height, 1)4차원으로 표현\n",
    "#stride = [1,1,1,1] #가운데 있는 '1' 2개만 의미 있는거임\n",
    "\n",
    "#conv2d = 한칸씩 점프하면서 결과데이터 뽑을 수 있는 함수  padding=\"VALID\" 하면 패딩하지마. size가 줄어. (padding=\"SAME\": 패딩해라/원본 image와 conv image은 size같음)\n",
    "conv2d=tf.nn.conv2d(image, weight, strides=[1,1,1,1], padding=\"VALID\")\n",
    "print(conv2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 1)\n",
      "(2, 2, 1, 3)\n",
      "(1, 2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "#Convolution example\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#image형태\n",
    "#1장의 이미지는 3차원형태의 데이터\n",
    "#(이미지의 개수, width, height, coloer)\n",
    "#(1,3,3,1)\n",
    "image = np.array([[[[1],[2],[3]],\n",
    "                  [[4],[5],[6]],\n",
    "                  [[7],[8],[9]]]], dtype=np.float32)  #(list안에 list넣어서 4차원의 np.array만들기)\n",
    "print(image.shape)\n",
    "#필터를 준비해야해요\n",
    "#(Width, height, color, 필터의 개수)\n",
    "#(2,2,1,3)\n",
    "\n",
    "weight = np.array([[[[1,-5,10]],[[1,-5,10]]],\n",
    "                   [[[1,-5,10]],[[1,-5,10]]]])\n",
    "\n",
    "print(weight.shape)\n",
    "#원본이미지 만들었고, 필터 만들었어요 => mapping시켜요!\n",
    "#mapping을 얼마의 간격으로 할건지도 정해요 - stride\n",
    "#stride지정(사실 2차원이면 되는데 행렬곱 연산을 위해서 어쩔수 없이 4차원으로 만들어줘야한다. (2개는 사용되지 않음)\n",
    "##(1, stride width, stride height, 1)4차원으로 표현\n",
    "#stride = [1,1,1,1] #가운데 있는 '1' 2개만 의미 있는거임\n",
    "\n",
    "#conv2d = 한칸씩 점프하면서 결과데이터 뽑을 수 있는 함수  padding=\"VALID\" 하면 패딩하지마. size가 줄어. (padding=\"SAME\": 패딩해라/원본 image와 conv image은 size같음)\n",
    "conv2d=tf.nn.conv2d(image, weight, strides=[1,1,1,1], padding=\"VALID\")\n",
    "print(conv2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 14, 14, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#MNIST 예제를 이용해서 하나의 이미지에 대한\n",
    "#convolutional image 5개를 생성해 보아요!\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Data Loading\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)  #실제로 Data만들어지고 압축파일로 쇽 들어감\n",
    "#Y축 label이 one_hot=True으로 생성되어 딸려나옴.\n",
    "\n",
    "#mnist의 학습용이미지의 images(이미지에 대한 정보 싹 들고 있는애)의 2번째 . 즉\n",
    "#training 이미지 중 2번째 이미지의 정보를 얻어와요!\n",
    "\n",
    "img = mnist.train.images[1]\n",
    "#print(img.shape)  #(784,) 튜플형태의 1차원 배열 데이터\n",
    "#2차원 형태로 바꾸자\n",
    "img = img.reshape(28,28)     #2차원 데이터로 변환\n",
    "plt.imshow(img, cmap=\"Greys\", interpolation=\"nearest\")    #이미지를 그리자!\n",
    "plt.show()\n",
    "\n",
    "#해당 이미지를 convolution 이미지로 변형\n",
    "#2차원 형태의 img를 4차원 형태의 img로 변환\n",
    "img =img.reshape(-1,28,28,1)   #(28,28)인 2차원을 4차원으로 바꾸자\n",
    "\n",
    "#이미지가 준비되었으니 필터를 준비\n",
    "#5개의 필터를 이용, 2x2짜리 필터를 이용\n",
    "#(2,2,1,5) (필터의 가로, 필터의 세로, depth(칼라), 필터(depth)) 필터의 \n",
    "\n",
    "W=tf.Variable(tf.random_normal([2,2,1,5]),name=\"filter\")\n",
    "conv2d=tf.nn.conv2d(img,W,strides=[1,2,2,1], padding=\"SAME\")    #2칸씩 움직이는 strides(2,2)\n",
    "\n",
    "#conv2d인 텐서플로 노드로 떨어진다.->sess.run으로 한번 실행시켜줘야 얘가 갖고 있는 배열 데이터를 얻을 수 있다.\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "conv2d=sess.run(conv2d)\n",
    "conv2d=np.swapaxes(conv2d,0,3)\n",
    "\n",
    "\n",
    "print(conv2d.shape)\n",
    "\n",
    "#(1, 14, 14, 5) = 14x14짜리 이미지가 5개 생성\n",
    "#새로 생성된 이미지를 plt를 이용하여 확인\n",
    "\n",
    "#배열의 축을 임의로 변경 - loop을 돌려야지 5개의 image를 화면에 찍을 수 있어서 loop을 돌리기 위해서\n",
    "#(1, 14, 14, 5) = (5, 14, 14, 1)\n",
    "# conv2d=np.swapaxes(conv2d,0,3)    #conv2d 인덱스 0과3을 스와핑시키자........ 1과 5의 위치를 바꾸자.\n",
    "# print(conv2d.shape)\n",
    "fig,axes=plt.subplots(1,5) #1행 5열짜리 subpolt을 생성   #axes는 subplot의 배열 (각각의 subplot에 대한 array)\n",
    "\n",
    "\n",
    "#enumerate 는 conv2d에 대한 데이터 툭툭 뽑으면서 index까지 같이 뽑음\n",
    "for idx,item in enumerate(conv2d):\n",
    "    axes[idx].imshow(item.reshape(14,14), cmap=\"Greys\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "(?, 14, 14, 32)\n",
      "(?, 7, 7, 32)\n",
      "(?, 7, 7, 64)\n",
      "(?, 7, 7, 64)\n",
      "Wall time: 878 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "####MNIST with CNN\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "\n",
    "#하나의 convolution layer 작업 (CONV - RELU - MAXpooling)\n",
    "# 0. tensorflow 그래프 초기화 \n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "##1. Data Loading & Data 정제\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)  #multinomial이니끼ㅏ one_hot encoding\n",
    "\n",
    "\n",
    "\n",
    "## 2. placeholder설정  --placeholder를 통해서 데이터를 받아서 그 다음이 진행되는거임.\n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "Y= tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "drop_rate = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "\n",
    "## 3. Convolution -Convolution은 image를 (x길이,y길이,이미지,컬럼) 4차원 형태로 표시\n",
    "#근데 placeholder 에 받아지는 데이터는 2차원 ->이걸 4차원형태로 바꿔야 한다.\n",
    "#입력데이터를 x_img 해서 4차원 형태로 받자. ->tf가 가지는 reshape란 함수를 사용 (x에 대한 shape 바꾸자)\n",
    "## 3.1 Convolution layer   \n",
    "x_img = tf.reshape(X,[-1,28,28,1])  #입력데이터를 (image의 개수, 가로, 세로, 컬럼-흑백이니까1)으로 reshape하자!\n",
    "#필터를 하나 만들겁니다 필터에 대한 데이터를 랜덤함수로 추출[2, 2, 1:이미지 색(흑백),  32(32개의 필터)]\n",
    "W1 = tf.Variable(tf.random_normal([2,2,1,32]),name = \"filter1\")\n",
    "L1 = tf.nn.conv2d(x_img,W1,strides=[1,2,2,1], padding =\"SAME\")\n",
    "\n",
    "print(L1.shape)\n",
    "#(?, 14, 14, 32) 필터32개 :32개의 image 14X14:(가로 14 세로 14)의 이미지.\n",
    "\n",
    "#CONV 작업 끝나면 RELU작업 해야함(쉽게 말해 sigmoid 작업. => sigmoid는 0~1사이의 값이라 계속 하면 0에 수렴하기때문에 sigmoid 안씀)\n",
    "L1= tf.nn.relu(L1)\n",
    "\n",
    "#맥스풀링 (렐루한 결과값 L1과 ksize) -큰거 만 딱딱 샘플링 가자\n",
    "L1= tf.nn.max_pool(L1,ksize=[1,2,2,1],\n",
    "                  strides=[1,2,2,1], padding=\"SAME\")  \n",
    "print(L1.shape)\n",
    "#(?, 7, 7, 32)\n",
    "# #####3.2 Convolution layer2\n",
    "#여기의 w값은 필터값을 랜덤하게 가기위한.\n",
    "W2 = tf.Variable(tf.random_normal([3,3,32,64]),name = \"filter1\")  #입력으로 들어오는 32맞춰\n",
    "L2 = tf.nn.conv2d(L1,W2,strides=[1,1,1,1], padding =\"SAME\")  #스트라이드 1칸씩 가자\n",
    "\n",
    "print(L2.shape)\n",
    "L2= tf.nn.relu(L2)\n",
    "#맥스풀링 (렐루한 결과값 L1과 ksize) -큰거 만 딱딱 샘플링 가자\n",
    "L2= tf.nn.max_pool(L2,ksize=[1,1,1,1],\n",
    "                  strides=[1,1,1,1], padding=\"SAME\")   ##stride 한칸씩만가자   \n",
    "print(L2.shape)\n",
    "L2 = tf.reshape(L2,[-1,7*7*64])  #4차원짜리를 2차원으로 바꿔야해.. \"컬럼수\":7x7x64\n",
    "\n",
    "##4. Neural Network 으로 돌아와야하니까 원래형태 2차원으로 바꺼\n",
    "##4.1 Weight &bias\n",
    "#여기의 W는 밑에는 weight 계산하는거니까 get_variable(xavier_initializer() 사용)\n",
    "W3 = tf.get_variable(\"weight3\", shape=[7*7*64,256], initializer=tf.contrib.layers.xavier_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 weight값을 0으로 주면 초기화 잘 안댐 >> 수학적으로 증명됨;\n",
    "# >> 그럼 어떻게 할까? >> 랜덤을 쓰지 말고 RBM 이라는 알고리즘에 따라 초기값을 부여하면 좀더 학습이 나아짐.\n",
    "# tf.Variable(tf.random_normal([784,256]), name=\"weight1\") >> tf.get_variable(\"weight1\", shape=[784,286],tf.contrib.layers.xavier_initializer())  (자비에(Xavier) 초기화법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpu_env] *",
   "language": "python",
   "name": "conda-env-cpu_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
