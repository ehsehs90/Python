{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요한 모듈 import \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 1. Data Loading\n",
    "\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 7, 7, 64)\n"
     ]
    }
   ],
   "source": [
    "# 2. Model정의(Tensorflow graph 생성)\n",
    "\n",
    "tf.reset_default_graph() #tensorflow graph초기화\n",
    "# 2.1 placeholder\n",
    "\n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "\n",
    "drop_rate = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "#2.2 Convolution\n",
    "## cNN은 이미지 학습에 최적화된 deep learning방법\n",
    "##입력받은 이미지의 형태가 4차원 배열\n",
    "##(이미지의 개수, 이미지의 width, 이미지의 height, color수)\n",
    "X_img = tf.reshape(X, [-1,28,28,1])\n",
    "\n",
    "# ## 2.3 Convolution Layer 1\n",
    "# ## filter 정의 => \n",
    "# filter의 shape(width, height, color, filter수)\n",
    "# filter1 = tf.Variable(tf.random_normal([3,3,1,32]))\n",
    "\n",
    "# #filter를 이용해서 Convolution image를 생성\n",
    "# L1 = tf.nn.conv2d(X_img, filter1, strides=[1,1,1,1], padding = \"SAME\")\n",
    "\n",
    "# #만들어진 Convolution에 Relu를 적용\n",
    "# L1 = tf.nn.relu(L1)\n",
    " \n",
    "# ##pooling 작업(resize, sampling 작업) => optional\n",
    "# #풀링작업하는이유 -> 필터적용해서 하다보면 이미지값이 계속 커짐.\n",
    "\n",
    "# L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "\n",
    "#필터 만들고 convolution 하고 relu작업까지 한방에 가능~(실제구현)\n",
    "L1 = tf.layers.conv2d(inputs=X_img, filters=32,\n",
    "                     kernel_size=[3,3], padding=\"SAME\",\n",
    "                     strides=1,activation=tf.nn.relu)\n",
    "L1 = tf.layers.max_pooling2d(inputs=L1,\n",
    "                            pool_size=[2,2], \n",
    "                            padding=\"SAME\",\n",
    "                            strides=2)\n",
    "\n",
    "#필터 만들고 convolution 하고 relu작업까지 한방에 가능~(실제구현)  << 2 >>\n",
    "L2 = tf.layers.conv2d(inputs=L1, filters=64,\n",
    "                     kernel_size=[3,3], padding=\"SAME\",\n",
    "                     strides=1,activation=tf.nn.relu)\n",
    "L2 = tf.layers.max_pooling2d(inputs=L2,\n",
    "                            pool_size=[2,2], \n",
    "                            padding=\"SAME\",\n",
    "                            strides=2)\n",
    "\n",
    "print(L2.shape)\n",
    "#(?, 7, 7, 64)\n",
    "#2.3 Neural Network\n",
    "#Convolution 의 결과를 Neural Network 의 입력으로 사용하기 위해 shape을 변경\n",
    "\n",
    "L2 = tf.reshape(L2,[-1,7*7*64])\n",
    "\n",
    "W1 = tf.get_variable(\"weight1\", shape=[7*7*64,256],\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]), name=\"bias1\")\n",
    "_layer1 = tf.nn.relu(tf.matmul(L2,W1)+b1)\n",
    "layer1= tf.layers.dropout(_layer1, rate=drop_rate)\n",
    "\n",
    "\n",
    "W2 = tf.get_variable(\"weight2\", shape=[256,10],\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([10]), name=\"bias2\")\n",
    "\n",
    "\n",
    "#hypothesis\n",
    "logits = tf.matmul(layer1,W2)+b2\n",
    "H= tf.nn.relu(logits)\n",
    "\n",
    "\n",
    "#cost function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "\n",
    "##train\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train=optimizer.minimize(cost)\n",
    "# #\n",
    "# #Session. 초기화\n",
    "# sess=tf.Session()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# #학습진행(batch처리)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Session. 초기화\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#학습진행(batch처리)\n",
    "\n",
    "\n",
    "#Accuracy 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 결국 우리 MNIST 예제는\n",
    "##### 입력한 이미지 1개에 대해 예측한 결과가 \n",
    "##### H 의 값으로 도출\n",
    "####Hypothesis -> 10개의 값으로 이루어짐(위에꺼 참조하면)\n",
    "##### [0.5 0.95 0.8 .0.34 0.12 0.34, ... ] 총 10개\n",
    "\n",
    "\n",
    "#####앙상블은 이런 model이 여러개 있어요!\n",
    "##즉, hypothesis 가 여러개 있어요\n",
    "###  H1-> [0.5 0.95 0.8 .0.34 0.12 0.34, ... ] 총 10개\n",
    "###  H2-> [0.2 0.3 0.4 .0.34 0.5 0.34, ... ] 총 10개\n",
    "###  H3-> [0.2 0.4 0.4 .0.34 0.5 0.34, ... ] 총 10개\n",
    "###  H4-> [0.1 0.5 0.7 .0.34 0.5 0.34, ... ] 총 10개\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####SUM => [1.06, 1.43, 2.4 3.5.. ]총 10개\n",
    "###최종 prediction은 SUM한 결과값을 가지고 예측\n",
    "#이게바로 앙상블. Hypothesis 를 10개 해서 모델 10개를 구하고 나눠서 진짜\n",
    "#최종 prediction 를구한다 -> 정확도 2%정도 올릴 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpu_env] *",
   "language": "python",
   "name": "conda-env-cpu_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
