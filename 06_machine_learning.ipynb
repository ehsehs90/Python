{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lending club data - 대출 csv파일 다운\n",
    "\n",
    "\n",
    "# Linux =>추후 하둡 시스템을 사용하기 위해서 간단한 형태로 시스템 명령어 위주로 학습\n",
    "\n",
    "\n",
    "# python =>기본 언어 특성\n",
    "# numpy => ndarray라는 자료구조와 여러가지 함수를 제공\n",
    "# pandas => 데이터분석(탐색적 데이터분석을 하기 위한 python module\n",
    "\n",
    "\n",
    "# machine learning(기계학습) -> 데이터 분석의 또 다른 방법\n",
    "\n",
    "# 머신러닝의 분류\n",
    "\n",
    "# -supervised Learning : Training 이라고 불리는 lable화 된 데이터를 이용해 학습예측모델을 생성한 후\n",
    "# \t\t\t예측모델을 이용해서 실제 데이터를  관측\n",
    "# \t=>우리가 관심이 있어하는 모델\n",
    "# \t=>다시 3가지 종류가 있어요\n",
    "# \t  1)Linear regression(선형회귀)  \n",
    "#  \t    추측한 결과값이 선형값(값의 분포가 제한이 없어요--- wide)\n",
    "# \t  2)Logistic regression          \n",
    "#             추측한 결과값이 논리값(2중의 1개)True/False\n",
    "#  \t  3)Multinomial Classification   \n",
    "#             추측한 결과값이 논리값(정해져있는 몇몇개 중 하나의 값)\n",
    "\n",
    "\n",
    "\n",
    "# -unsupervised Learning : training set 을 통해서 학습\n",
    "# \t\t\t데이터에 lable이 없어요!\n",
    "# \t\t\t비슷한 데이터끼리 clustering\n",
    "\n",
    "\n",
    "# import tensorflow as tf\n",
    "# ->외부모듈 설치피료\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. tensorflow module설치( cpu용)\n",
    "## > conda install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'helloworld'\n",
      "helloworld\n"
     ]
    }
   ],
   "source": [
    "## 2.Hello world 출력\n",
    "## 상수를 하나 만들어요 (상수 Node 생성)\n",
    "## Tensorflow Node는 숫자 연산과 데이터 입출력을 담당하는 기능\n",
    "##Session 을 이용해서 Node를 실행시켜야지\n",
    "##Node가 가지고 있는 데이터를 출력할 수 있어요.\n",
    "my_node = tf.constant(\"helloworld\")   ##상수 만드는 법\n",
    "\n",
    "##세션을 이용해서 노드를 출력해야 노드 값이 나온다.\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "#print(my_node)\n",
    "print(sess.run(my_node))    ##앞의 b는 binary text를 나타냄\n",
    "print(sess.run(my_node).decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TensorFlow : Google이 만든 machine library\n",
    "##              open source library\n",
    "##              수학적 계산을 하기 위한 library\n",
    "##              data flow graph를 이용해요!\n",
    "\n",
    "\n",
    "## data flow graph는 Node와 Edge로 구성된 방향성 있는 graph\n",
    "\n",
    "## Node : 데이터의 입출력과 수학적 연산\n",
    "## Edge : Tensor를 Node로 실어 나르는 역할\n",
    "## Tensor : 동적 크기의 다차원배열을 지칭\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0\n",
      "[10.0, 20.0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "node1 = tf.constant(10,dtype=tf.float32)\n",
    "node2 = tf.constant(20,dtype=tf.float32)\n",
    "\n",
    "node3 = node1 + node2\n",
    "\n",
    "\n",
    "\n",
    "##그래프를 실행시키기위해 runner역할을 하는\n",
    "##Session객체가 있어야 해요b\n",
    "\n",
    "sess= tf.Session()\n",
    "\n",
    "sess.run(node1)\n",
    "sess.run(node2)\n",
    "sess.run(node3)\n",
    "\n",
    "print(sess.run(node3))\n",
    "print(sess.run([node1,node2]))  ##복수개의 노드를 실행시키려면 안에 배열형태로 나타내야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#placeholder를 이용\n",
    "#2개의 수를 입력으로 받아서 더하는 프로그램\n",
    "node1 = tf.placeholder(dtype=tf.float32)\n",
    "node2 = tf.placeholder(dtype=tf.float32)    #아직 값은 없다. 말그대로 공간임..\n",
    "\n",
    "node3 = node1 + node2\n",
    "sess= tf.Session()\n",
    "result = sess.run(node3, feed_dict={node1:10,node2:20})  ##dict형태로 먹이를 줄거에요. key/value의 쌍으로 placeholder에 각각 매핑.\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_37:0\", shape=(3,), dtype=int32)\n",
      "Tensor(\"Cast_1:0\", shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "node1= tf.constant([10,20,30], dtype=tf.int32)\n",
    "print(node1)\n",
    "\n",
    "node2=tf.cast(node1, dtype=tf.float32)           ##cast = 형을 변환할거에요!\n",
    "print(node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "[2.2427902],[-2.7517965],1.107126235961914\n",
      "[1.5905594],[-1.3424801],0.2597919702529907\n",
      "[1.286868],[-0.6521186],0.0613003671169281\n",
      "[1.1393479],[-0.31677082],0.014464388601481915\n",
      "[1.0676892],[-0.1538735],0.0034130134154111147\n",
      "[1.0328804],[-0.07474489],0.0008053293568082154\n",
      "[1.0159718],[-0.0363077],0.00019002439512405545\n",
      "[1.0077584],[-0.01763679],4.4837983296019956e-05\n",
      "[1.0037688],[-0.00856727],1.0580140042293351e-05\n",
      "[1.001831],[-0.00416213],2.497351488273125e-06\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "##training data set\n",
    "\n",
    "x = [1,2,3]\n",
    "y = [1,2,3]  #label\n",
    "\n",
    "\n",
    "# 선형회귀(linear regression)\n",
    "# 가장 큰 목표는 가설의 완성\n",
    "\n",
    "# 가설(hypothesis) = Wx + b\n",
    "# W와 b를 정의\n",
    "\n",
    "# Weight & bias 정의\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\")    # W값 = 1차원 1개 \"Weight\"= 해당 tensoflow를 내부적으로 사용하기 위한 이름\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Hypothesis(가설)\n",
    "#우리의 최종 목적은 training data에 가장 근접한\n",
    "#Hypothesis를 만드는것(W와b를 결정)\n",
    "#잘 만들어진 가설은W 가 1에 가깝고 b가 0에 가까워야 한다. cost값은 최소값\n",
    " \n",
    "H = W*x + b     #결과값 당연히 node.\n",
    "\n",
    "#cost(loss) function    --최적의H를 만들기 위해서 필요.\n",
    "#우리의 목적은 cost함수를 최소로 만드는 W와 b를 구하는 것.\n",
    "cost = tf.reduce_mean(tf.square(H-y))                      #reduce_mean() : 평균구하는 함수\n",
    "\n",
    "##cost function minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)    #0.01이라는 러닝메이트를 이용해서 위쪽의 cost함수를최소화 시키기 위해 도와주는 함수를 만들자.\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "#텐서플로가 제공하는 최소화시키는놈을 하나 만들어서\n",
    "#cost함수를 최소화할거다.\n",
    "\n",
    "\n",
    "\n",
    "##runner 생성\n",
    "sess = tf.Session()\n",
    "##Global variable의 초기화\n",
    "sess.run(tf.global_variables_initializer())   #variable이라는 W와 b사용하기 때문에 초기화작업한번 진행하즈아~\n",
    "\n",
    "\n",
    "## 학습진행\n",
    "for step in range(3000):\n",
    "    _, w_val, b_val, cost_val =  sess.run([train,W,b,cost])      ##sess.run해가지고 node를 4개 읽어가 각각에 매핑되는 값을 떄리박아\n",
    "    \n",
    "    if step % 300 == 0:                 # 300 600 900 일떄만 print해서 찍겠습니다\n",
    "        print(\"{},{},{}\".format(w_val,b_val,cost_val))\n",
    "        \n",
    "## W_val        b_val      cost_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.22738\n",
      "0.024683349\n",
      "0.004084099\n",
      "0.00067575654\n",
      "0.00011179744\n",
      "1.8500983e-05\n",
      "3.0626447e-06\n",
      "5.076199e-07\n",
      "8.4386215e-08\n",
      "1.408489e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([900.988], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "##training data set(받아드려서 프로그램으로 넘기기위한 공간)\n",
    "x=tf.placeholder(dtype=tf.float32)\n",
    "y=tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "\n",
    "##training data set\n",
    "x_data=[1,2,3,4]\n",
    "y_data=[4,7,10,13]\n",
    "\n",
    "\n",
    "#Weight & bias ---W값의 초기값= random하게 0에 근사한 값으로 주자(아무거나 주면 이상해짐)\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\")  ##weight라는 이름으로 w에 대한 tensorflow변수 선언\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "#Hypothesis\n",
    "H = W*x + b\n",
    "\n",
    "#cost(loss) function  : 어떻게하면 저 1차함수graph가 trainingData에 가장 근접하까.....?하고 만든거임\n",
    "cost = tf.reduce_mean(tf.square(H-y))   ##기본적인 cost function : 직선 -원래데이타 (차) 제곱의 형태로 만들었따. 2차함수\n",
    "                \n",
    "##cost function 을 최소화 시키기 위한 작업 ::경사하강법:gredient decent:(미어캣미어캣 찾다 가장 경사 급한쪽으로 가는 거) -\n",
    "##loop를 돌아야함//알고리즘 복잡함   ::: tensorflow가 자체적으로 제공해주는 노드 있음 gradientDecentOptimizer\n",
    "##learning_rate 값이 작으면 경사하강법 할때 경사 젤 급한쪽 찾아도 아주찔끔찔끔씩 움직인다.우리는 일반적으로 0.01쓸거임\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)   ##현재위치에서 찾아서 0.01이동\n",
    "train = optimizer.minimize(cost) ##이거 실행하면 내부적으로 cost 최소화되면서 w.b값을 잡아준다              ##반복해야하기 떄문에 노드잡아준다.\n",
    "                \n",
    "                \n",
    "#tensorflow graph동작시키려면 runner필요함 -> runner는 Session필요&& 초기화\n",
    "                \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())    ##tensorflow가 갖고있는 전역변수들을 초기화 시켜준다\n",
    "                \n",
    "                \n",
    "                \n",
    "##준비 끝났으면 학습 가즈악~! 3000번 반복 가즈앗\n",
    "for step in range(3000):\n",
    "    _, cost_val = sess.run([train,cost],feed_dict={x:x_data,y:y_data})    ##cost값이 최소화 되는걸로 학습이 제대로 되는지 확인하기 위해  뽑아서 보기 (변수 _: 사용하지 않겠다는 의미)\n",
    "##뭘 줘야해? 먹이데이터를 줘야함 - 데이터가 있어야 실행이.\n",
    "    if step% 300 == 0:   ##300번마다\n",
    "        print(cost_val)\n",
    "                \n",
    "##prediction ::최종목적인H\n",
    "sess.run(H, feed_dict={x :[300]})      ## x라는 값에 내가 알고싶은 파라미터 ㄱㄱ(주의! x는 배열형태로 줬다 위에서 )\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cost function 은 어떤 형태의 함수여야 하냐! convex function이여야 함\n",
    "#Linear regression. 선형적인 데이터여야 한다.\n",
    "#따라서 앞으로 쓸 데이터가 선형적인지 아닌지도 확인하기 위해 matplotlib.pyplot 도 import시켰다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ozone</th>\n",
       "      <th>Solar.R</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>74</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.3</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ozone  Solar.R  Wind  Temp  Month  Day\n",
       "0   41.0    190.0   7.4    67      5    1\n",
       "1   36.0    118.0   8.0    72      5    2\n",
       "2   12.0    149.0  12.6    74      5    3\n",
       "3   18.0    313.0  11.5    62      5    4\n",
       "4    NaN      NaN  14.3    56      5    5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/ozone/ozone.csv\", sep=\",\" )\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153, 2)\n",
      "(116, 2)\n"
     ]
    }
   ],
   "source": [
    "##온도에 따른 오존량 예측\n",
    "##필요한 column만 추출합시다\n",
    "\n",
    "df2 = df[['Ozone','Temp']]   #fancy indexing\n",
    "#display(df2.head())\n",
    "#결치값 처리(제거)\n",
    "\n",
    "df3=df2.dropna(how=\"any\", inplace=False)   #how=\"all\" : Ozone, Temp 에 둘다 NaN인경우 지워.\n",
    "\n",
    "print(df2.shape)\n",
    "print(df3.shape)  ##결치값 제거한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#이렇게 준비한 데이터가 linear 한 데이터인지 확인\n",
    "plt.scatter(df3[\"Temp\"],df3[\"Ozone\"])                       ## x_data= 온도(Temp) y_data=오존(Ozone) 해서 그래프 보겠다\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##데이타를 보건데 완벽한 선형은 아닌듯 보인다.\n",
    "##저기 보면 하나 딸랑 튀어난 이상한 점 있따 => 정제해야할 필요가 있어보인다.\n",
    "## Why? 저런이상한 데이터가 머신러닝에 가중치를 많이줌.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:0.14222897589206696\n",
      "cost:0.039208076894283295\n",
      "cost:0.031333714723587036\n",
      "cost:0.02665695734322071\n",
      "cost:0.023879336193203926\n",
      "cost:0.022229647263884544\n",
      "cost:0.02124985307455063\n",
      "cost:0.02066793106496334\n",
      "cost:0.020322319120168686\n",
      "cost:0.02011704444885254\n"
     ]
    }
   ],
   "source": [
    "##placeholder\n",
    "\n",
    "\n",
    "x=tf.placeholder(dtype=tf.float32)\n",
    "y=tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "#training data set\n",
    "\n",
    "#데이터 정제 가즈아~!~!(밑에 내려갔따 올라오심)\n",
    "#normalization : (요소값 - 최소값) / (최대값 - 최소값) : 무조건 1보다 작은값으로 떨어짐( 0이상 1이하)\n",
    "x_data = (df3[\"Temp\"]-df3[\"Temp\"].min()) / (df3[\"Temp\"].max() - df3[\"Temp\"].min())  ##DataFrame 에서 Series형태로 데이터 뽑아씀\n",
    "y_data = (df3[\"Ozone\"]-df3[\"Ozone\"].min())/ (df3[\"Ozone\"].max() - df3[\"Ozone\"].min())\n",
    "\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\") \n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "#Hypothesis\n",
    "H= W*x +b\n",
    "\n",
    "#cost function\n",
    "cost = tf.reduce_mean(tf.square(H-y))\n",
    "\n",
    "#최소화 노드 생성\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01) \n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "#Session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#학습(train)\n",
    "for step in range(3000):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={x:x_data, y:y_data})\n",
    "    \n",
    "    if step % 300 == 0:\n",
    "        print(\"cost:{}\".format(cost_val))\n",
    "\n",
    "        \n",
    "#display(df3) # x와 y의 데이터 값 차이가 꽤 난다. 그래서 자꾸 발산한다. 이걸 정규화 할 필요가 있다. (Row data 정규화)\n",
    "##그래야 제대로 된 costfunction이 일어나고 제대로 된 학습이 생길 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization : (요소값 - 최소값 ) / (최대값 - 최소값) : 무조건 1보다 작은값으로 떨어짐( 0이상 1이하)\n",
    "##따라서 x, y 값은 무조건 0~1사이 값으로 정규화 할 수 있습니다.\n",
    "###standardization : (요소값 - 평균) / 표준편차\n",
    "\n",
    "#이 두가지 기법중 하나를 사용해 데이터를 정제한 후 학습시켜야 함.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177601.03\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "##변수가 1개일 때의 hypothesis\n",
    "#Hx = Wx+b\n",
    "#변수가 3개일 때의 hypothesis\n",
    "#H(x1,x2,x3) = w1x1+ w2x2+ w3x3 +b\n",
    "\n",
    "#이렇게 많은 입력변수를 어떻게 처리할 까?\n",
    "#-Matrix 이용!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# Matrix multiplication\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "##training data set\n",
    "x_data = [[73,80,75],\n",
    "         [93,88,93],\n",
    "         [89,91,90],\n",
    "         [96,98,100],\n",
    "         [73,66,70]]\n",
    "\n",
    "y_data = [[152],[185],[180],[196],[142]]\n",
    "\n",
    "#placeholder\n",
    "\n",
    "X = tf.placeholder(shape=[None,3],dtype=tf.float32)  ##[5,3]\n",
    "##이렇게 shape(내가 입력하는값의 shape)을 해줄 수 있는데 받아드릴때  Matrix 형태로 상관하지 않고 넣겠다 머 이런너낌[None,3]으로 가자\n",
    "Y = tf.placeholder(shape=[None,1],dtype=tf.float32) ##[5,1]\n",
    "\n",
    "##x와 w 를 곱해 y로 떨어져야 한다. (5.3)   (3.1)   (5.1)  따라서 W는 (3.1) 입니다\n",
    "#Weight & bias\n",
    "W = tf.Variable(tf.random_normal([3,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "#H= W*x+b\n",
    "H= tf.matmul(X,W)+b\n",
    "##텐서플로우가 제공하는 행렬 곱 함수\n",
    "\n",
    "#Cost function\n",
    "cost=tf.reduce_mean(tf.square(H-Y))  #원래 일차원 벡터였던 h-x. 지금현재는 매트릭스인데 알아서(같은 행과 같은 열의) 차의 제곱알아서 해줌squre이\n",
    "\n",
    "#학습노드 생성\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "#Session & 초기화\n",
    "sess= tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(3000):\n",
    "        _, cost_val = sess.run([train,cost], feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 300 ==0:\n",
    "            print(cost_val)\n",
    "\n",
    "            \n",
    "#정규화 안하고 학습시켜주면 발산해버림 ->왜? 정규호ㅏ 안했자나\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(111, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(111, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Temp가지고 Ozone 예측 가즈아~\n",
    "df33=df[[\"Solar.R\",\"Temp\",\"Wind\",\"Ozone\"]]\n",
    "df44=df33.dropna(how=\"any\", inplace=False) ##정제한 녀석.\n",
    "\n",
    "df55=df44[[\"Solar.R\",\"Temp\",\"Wind\"]]          ##정제한 녀석을 갖고 column get.\n",
    "df66=df44[[\"Ozone\"]]                          ##정제한 녀석을 갖고 column get.\n",
    "display(df44.shape)\n",
    "display(df55.shape)\n",
    "display(df66.shape)\n",
    "\n",
    "#*************안되는 이유 remind*************\n",
    "# #df6=df[[\"Ozone\"]]\n",
    "# df7=df6.dropna(how=\"any\", inplace=False)\n",
    "# display(df7)\n",
    "# display(df7.head())\n",
    "# display(df7.shape)\n",
    "# #x_data = (df3[\"Temp\"]-df3[\"Temp\"].min()) / (df3[\"Temp\"].max() - df3[\"Temp\"].min())  ##DataFrame 에서 Series형태로 데이터 뽑아씀\n",
    "#y_data = (df3[\"Ozone\"]-df3[\"Ozone\"].min())/ (df3[\"Ozone\"].max() - df3[\"Ozone\"].min())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.832343\n",
      "0.1998521\n",
      "0.11485954\n",
      "0.069115765\n",
      "0.04446859\n",
      "0.031175893\n",
      "0.024000423\n",
      "0.020123266\n",
      "0.018025763\n",
      "0.016889183\n"
     ]
    }
   ],
   "source": [
    "#training data set\n",
    "x_data = (df55-df55.min()) / (df55.max() - df55.min())\n",
    "          \n",
    "          \n",
    "#y_data = [[(df7[\"Ozone\"]-df7[\"Ozone\"].min()) / (df7[\"Ozone\"].max() - df7[\"Ozone\"].min())]]\n",
    "y_data1 = df66[\"Ozone\"].values.reshape(-1,1)  ##-1은 뒤에 값 따르겠다는 뜻임.\n",
    "y_data = (y_data1- y_data1.min())/(y_data1.max()-y_data1.min())\n",
    "\n",
    "#placeholder\n",
    "\n",
    "X = tf.placeholder(shape=[None,3],dtype=tf.float32)  ##[5,3]\n",
    "##이렇게 shape(내가 입력하는값의 shape)을 해줄 수 있는데 받아드릴때  Matrix 형태로 상관하지 않고 넣겠다 머 이런너낌[None,3]으로 가자\n",
    "Y = tf.placeholder(shape=[None,1],dtype=tf.float32) ##[5,1]\n",
    "\n",
    "##x와 w 를 곱해 y로 떨어져야 한다. (5.3)   (3.1)   (5.1)  따라서 W는 (3.1) 입니다\n",
    "#Weight & bias\n",
    "W = tf.Variable(tf.random_normal([3,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# Hypothesis\n",
    "#H= W*x+b\n",
    "H= tf.matmul(X,W)+b\n",
    "##텐서플로우가 제공하는 행렬 곱 함수\n",
    "\n",
    "#Cost function\n",
    "cost=tf.reduce_mean(tf.square(H-Y))  #원래 일차원 벡터였던 h-x. 지금현재는 매트릭스인데 알아서(같은 행과 같은 열의) 차의 제곱알아서 해줌squre이\n",
    "\n",
    "#학습노드 생성\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "#Session & 초기화\n",
    "sess= tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(3000):\n",
    "        _, cost_val = sess.run([train,cost], feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 300 ==0:\n",
    "            print(cost_val)\n",
    "\n",
    "            \n",
    "#정규화 안하고 학습시켜주면 발산해버림 ->왜? 정규호ㅏ 안했자나\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "1.1316998\n",
      "0.01749038\n",
      "0.015794195\n",
      "0.015550712\n",
      "0.015513217\n",
      "0.015507438\n",
      "0.015506547\n",
      "0.015506409\n",
      "0.015506388\n",
      "0.015506386\n",
      "[[47.17387]]\n"
     ]
    }
   ],
   "source": [
    "##multiple linear regression\n",
    "##Ozone data 학습 및 예측\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = pd.read_csv(\"./data/ozone/ozone.csv\", sep=\",\")\n",
    "\n",
    "#필요한 컬럼만 추출\n",
    "df.drop([\"Month\",\"Day\"],axis=1, inplace=True)   ##저거 2개빼면 Ozone solar.r wind temp 이케남음\n",
    "#결치값 처리(제거)\n",
    "df.dropna(how=\"any\", inplace=True)\n",
    "# x데이터 추출\n",
    "df_x = df.drop(\"Ozone\",axis=1, inplace=False)\n",
    "# y데이터 추출\n",
    "df_y = df[\"Ozone\"]\n",
    "#display(df_x)\n",
    "\n",
    "#training data set\n",
    "x_data = MinMaxScaler().fit_transform(df_x.values)\n",
    "y_data = MinMaxScaler().fit_transform(df_y.values.reshape(-1,1))\n",
    "\n",
    "#display(y_data)\n",
    "# x_data = MinMaxScaler().fit_transform(df_x.values)\n",
    "# y_value = df_y.values # 1차원 배열형태로 빠지게 되요 백터형태로\n",
    "#                      # 그러나 우리가필요한건 2차원 메트릭스 형태!!\n",
    "# y_data = MinMaxScaler().fit_transform(y_value.reshape(-1,1)) # 요로코롬하면 2차원 메트릭스로 바뀜\n",
    "\n",
    "\n",
    "#placeholder\n",
    "\n",
    "X=tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "Y=tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "#Weight & bias\n",
    "W= tf.Variable(tf.random_normal([3,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "#Hypothesis\n",
    "H=tf.matmul(X,W)+b\n",
    "\n",
    "#cost function\n",
    "cost= tf.reduce_mean(tf.square(H-Y))\n",
    "\n",
    "#train node생성\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "#Session. & 초기화\n",
    "sess= tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#학습진행\n",
    "for step in range(30000):\n",
    "    _, cost_val = sess.run([train,cost],feed_dict={X:x_data ,Y:y_data})\n",
    "    \n",
    "    if step % 3000 == 0:\n",
    "        print(cost_val)\n",
    "    \n",
    "    \n",
    "#prediction\n",
    "print(sess.run(H, feed_dict={X:[[190,4.7,67]]}))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning의 3가지 분류\n",
    "# 1. supervised learning(지도학습)\n",
    "#    => training data에 label이 존재하지 않아요!\n",
    "#    => clustering 작업이 일반적으로 진행\n",
    "# 3. 강화학습\n",
    "#    => 상점과 벌점을 이용하여 점점 더 좋은 방향으로\n",
    "#       학습해 나가는 방식\n",
    "\n",
    "## Supervised Leaning (지도학습)\n",
    "## 1. single linear regression( 단순 선형회귀 )\n",
    "## 2. multiple linear regression( 다중 선형회귀 )\n",
    "##    => matrix\n",
    "## 3. Logistic regression ( binary classification )\n",
    "## 4. Multinomial classification\n",
    "\n",
    "## ++ 추가 내용\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##기본 MNIST 예제(multinomial classification)\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt   ##차트에 관한 라이브러리 하나 공부하기\n",
    "import numpy as np  \n",
    "from tensorflow.examples.tutorials.mnist import input_data  ##28*28 ##처음에 warning나오고 두번째 실행시키면 warning사라짐.(왜 난 한번에 됐지?)\n",
    "\n",
    "#Data Loading\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)  \n",
    "##Data set 을 불러들이는 코드작성. (input data란 객체 제공해줌. read_data_set이란 함수 제공해줌)\n",
    "#one_hot encoding처리까지 자동적으로 해줌\n",
    "\n",
    "##데이터 확인\n",
    "print(mnist.train.num_examples) #학습용 데이터의 개수\n",
    "print(mnist.train.images.shape) #(55000,784)\n",
    "#우리가 불러들인 mnist에서 학습용 데이터(image/label) 중 image data볼거에요. (가로 28,세로 28 픽셀정보가 담긴 Data)\n",
    "# 28X28이미지를 1차원 형태로 저장\n",
    "\n",
    "print(mnist.train.labels.shape)\n",
    "\n",
    "plt.imshow(mnist.train.images[0].reshape(28,28),\n",
    "           cmap=\"Greys\", interpolation=\"nearest\")  ##55000개중 첫번째 이미지에 대한 픽셀정보. (이미지 를 x,y축에 맞춰 그려야하니까 1차원을 2차원으로 reshape해주는거임)\n",
    "plt.show()\n",
    "print(mnist.train.labels[0])\n",
    "\n",
    "\n",
    "#placeholder\n",
    "X=tf.placeholder(shape=[None,784], dtype=tf.float32)  ##행부분은 나중에 예측할때 문제가 생기므로 55000이아닌None, 열부분만 표기\n",
    "Y=tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "\n",
    "\n",
    "#Weight & bias\n",
    "W=tf.Variable(tf.random_normal([784,10]), name=\"weight\")\n",
    "b=tf.Variable(tf.random_normal([10]), name=\"bias\")  ##여러개의 로직이 합쳐져서 들어감\n",
    "\n",
    "\n",
    "#Hypothesis  (우리 multinomial/ softmax를 사용해 각각의 확률을 구해서 가장 높은 함수 구해야함)\n",
    "logits =tf.matmul(X,W)+b\n",
    "H = tf.nn.softmax(logits)   #softmax= 어떤게 확률이 가장 높아?\n",
    "\n",
    "\n",
    "\n",
    "#cost function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "\n",
    "\n",
    "#train node생성\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train=optimizer.minimize(cost)\n",
    "\n",
    "#Session & 초기화\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#사용하는 데이터의 크기가 상당히 커요!\n",
    "#데이터의 크기에 상관없이 학습하는 방식이 필요!(잘라서 읽어들이는 코드로의 변형이 필요)\n",
    "#epoch : traing data를 1번 학습 시키는 것.\n",
    "\n",
    "#학습진행 (DataSize가 크기 때문에 전체 반복 횟수를 줄임. 55000에 컬럼 782개..)\n",
    "# for step in range(3000):\n",
    "#     _, cost_val = sess.run([train,cost], feed_dict={X:mnist.train.images,Y:mnist.train.labels})\n",
    "    \n",
    "#     if step%300 ==0:\n",
    "#         print(cost_val)\n",
    "\n",
    "    \n",
    "training_epoch = 30 #(30번 반복한다는 뜻)\n",
    "batch_size = 100 # 55000개의 행을 다 읽어들이는게 아니라 100 개의 행을 읽어서 반복 학습.(100개씩 잘라서 55000개를 읽을거에요-2중루프 필요. 에폭포르푸, 배치포루프)\n",
    "\n",
    "for step in range(training_epoch):\n",
    "    num_of_iter = int(mnist.train.num_examples / batch_size )\n",
    "    cost_val = 0\n",
    "    for i in range(num_of_iter):\n",
    "        batch_x, batch_y =mnist.train.next_batch(batch_size)\n",
    "        _, cost_val = sess.run([train,cost],\n",
    "                              feed_dict={X:batch_x,Y:batch_y})\n",
    "    if step % 30 ==0:\n",
    "        print(cost_val)\n",
    "\n",
    "#Accuracy 측정\n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy =tf.reduce_mean(tf.cast(correct,dtype=tf.float32))\n",
    "\n",
    "result=sess.run(accuracy, feed_dict={X:mnist.test.images, Y:mnist.test.labels})\n",
    "print(\"정확도 : {}\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99988234\n",
      "0.49427626\n",
      "0.40347472\n",
      "0.37123266\n",
      "0.3482656\n",
      "0.32875478\n",
      "0.31160462\n",
      "0.29634604\n",
      "0.28265727\n",
      "0.27029023\n",
      "정확도:1.0\n"
     ]
    }
   ],
   "source": [
    "#logistic regression 을 이용하여 AND연산을 학습\n",
    "#\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#training data set\n",
    "x_data =[[0,0],\n",
    "         [0,1],\n",
    "         [1,0],\n",
    "         [1,1]]\n",
    "y_data = [[0],[0],[0],[1]]\n",
    "\n",
    "#placeholder\n",
    "X=tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "Y=tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "#Weight & bias\n",
    "W=tf.Variable(tf.random_normal([2,1], name=\"weight\"))\n",
    "b=tf.Variable(tf.random_normal([1], name=\"bias\"))\n",
    "\n",
    "# hypothesis\n",
    "logits = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logits)\n",
    "\n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels = Y))\n",
    "\n",
    "#train node\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train=optimizer.minimize(cost)\n",
    "\n",
    "\n",
    "#session&초기화\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#학습\n",
    "for step in range(3000):\n",
    "    _, cost_val = sess.run([train,cost],\n",
    "                          feed_dict={X:x_data,Y:y_data})\n",
    "    if step % 300 ==0:\n",
    "        print(cost_val)\n",
    "        \n",
    "#Accuracy 측정\n",
    "predict = tf.cast(H>0.5, dtype=tf.float32)\n",
    "correct = tf.equal(predict, Y)\n",
    "accuracy =tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(\"정확도:{}\".format(sess.run(accuracy, feed_dict={X:x_data,Y:y_data})))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71427846\n",
      "0.32564753\n",
      "0.035244994\n",
      "0.017132524\n",
      "0.0111991875\n",
      "0.008287988\n",
      "0.006566569\n",
      "0.0054319277\n",
      "0.0046287947\n",
      "0.0040309196\n",
      "정확도:1.0\n"
     ]
    }
   ],
   "source": [
    "#NN을 이용하여 XOR 연산을 학습\n",
    "#\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#training data set (XOR에 대한 진리표)\n",
    "x_data =[[0,0],\n",
    "         [0,1],\n",
    "         [1,0],\n",
    "         [1,1]]\n",
    "y_data = [[0],[1],[1],[0]]\n",
    "\n",
    "#placeholder\n",
    "X=tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "Y=tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "#Weight & bias\n",
    "W1=tf.Variable(tf.random_normal([2,2]), name=\"weight1\")  \n",
    "#10 여기 숫자는 정해져있는게 없음 2번째 layeer에 내가 몇개의 input을 쓸거냐 \n",
    "#에따라 달라짐.숫자가 클수록 더 많이 학습한다는 뜻임.\n",
    "b1=tf.Variable(tf.random_normal([2]), name=\"bias1\")\n",
    "layer1=tf.sigmoid(tf.matmul(X,W1)+b1)\n",
    "\n",
    "W2=tf.Variable(tf.random_normal([2,1]), name=\"weight2\")  #2 2  2output과 input과의 갯수만 맞추자\n",
    "b2=tf.Variable(tf.random_normal([1]), name=\"bias2\") #너의 output은 y와 맞춰\n",
    "#layer(계층)을 더 늘리면 학습이 더 잘 이루어짐.\n",
    "# hypothesis\n",
    "logits = tf.matmul(layer1,W) + b\n",
    "H = tf.sigmoid(logits)\n",
    "\n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels = Y))\n",
    "\n",
    "#train node\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train=optimizer.minimize(cost)\n",
    "\n",
    "\n",
    "#session&초기화\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#학습\n",
    "for step in range(30000):\n",
    "    _, cost_val = sess.run([train,cost],\n",
    "                          feed_dict={X:x_data,Y:y_data})\n",
    "    if step % 3000 ==0:\n",
    "        print(cost_val)\n",
    "        \n",
    "#Accuracy 측정\n",
    "predict = tf.cast(H>0.5, dtype=tf.float32)\n",
    "correct = tf.equal(predict, Y)\n",
    "accuracy =tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(\"정확도:{}\".format(sess.run(accuracy, feed_dict={X:x_data,Y:y_data})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MNIST(Neural Network)\n",
    "## tensorflor에 example로 표함된 MNIST예제를\n",
    "## NN으로 학습. (accuracy=>95%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mnist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8f666cf66868>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m     \u001b[0mnum_of_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_examples\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m     \u001b[0mcost_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_of_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mnist' is not defined"
     ]
    }
   ],
   "source": [
    "##기본 MNIST 예제(multinomial classification)\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt   ##차트에 관한 라이브러리 하나 공부하기\n",
    "import numpy as np  \n",
    "from tensorflow.examples.tutorials.mnist import input_data  ##28*28 ##처음에 warning나오고 두번째 실행시키면 warning사라짐.(왜 난 한번에 됐지?)\n",
    "\n",
    "# #Data Loading\n",
    "# mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)  \n",
    "# ##Data set 을 불러들이는 코드작성. (input data란 객체 제공해줌. read_data_set이란 함수 제공해줌)\n",
    "# #one_hot encoding처리까지 자동적으로 해줌\n",
    "\n",
    "# ##데이터 확인\n",
    "# print(mnist.train.num_examples) #학습용 데이터의 개수\n",
    "# print(mnist.train.images.shape) #(55000,784)\n",
    "# #우리가 불러들인 mnist에서 학습용 데이터(image/label) 중 image data볼거에요. (가로 28,세로 28 픽셀정보가 담긴 Data)\n",
    "# # 28X28이미지를 1차원 형태로 저장\n",
    "\n",
    "# print(mnist.train.labels.shape)\n",
    "\n",
    "# plt.imshow(mnist.train.images[0].reshape(28,28),\n",
    "#            cmap=\"Greys\", interpolation=\"nearest\")  ##55000개중 첫번째 이미지에 대한 픽셀정보. (이미지 를 x,y축에 맞춰 그려야하니까 1차원을 2차원으로 reshape해주는거임)\n",
    "# plt.show()\n",
    "# print(mnist.train.labels[0])\n",
    "\n",
    "\n",
    "#placeholder\n",
    "X=tf.placeholder(shape=[None,784], dtype=tf.float32)  ##행부분은 나중에 예측할때 문제가 생기므로 55000이아닌None, 열부분만 표기\n",
    "Y=tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "\n",
    "\n",
    "#Weight & bias\n",
    "W=tf.Variable(tf.random_normal([784,10]), name=\"weight\")\n",
    "b=tf.Variable(tf.random_normal([10]), name=\"bias\")  ##여러개의 로직이 합쳐져서 들어감\n",
    "\n",
    "\n",
    "#Hypothesis  (우리 multinomial/ softmax를 사용해 각각의 확률을 구해서 가장 높은 함수 구해야함)\n",
    "logits =tf.matmul(X,W)+b\n",
    "H = tf.nn.softmax(logits)   #softmax= 어떤게 확률이 가장 높아?\n",
    "\n",
    "\n",
    "\n",
    "#cost function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "\n",
    "\n",
    "#train node생성\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train=optimizer.minimize(cost)\n",
    "\n",
    "#Session & 초기화\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#사용하는 데이터의 크기가 상당히 커요!\n",
    "#데이터의 크기에 상관없이 학습하는 방식이 필요!(잘라서 읽어들이는 코드로의 변형이 필요)\n",
    "#epoch : traing data를 1번 학습 시키는 것.\n",
    "\n",
    "#학습진행 (DataSize가 크기 때문에 전체 반복 횟수를 줄임. 55000에 컬럼 782개..)\n",
    "# for step in range(3000):\n",
    "#     _, cost_val = sess.run([train,cost], feed_dict={X:mnist.train.images,Y:mnist.train.labels})\n",
    "    \n",
    "#     if step%300 ==0:\n",
    "#         print(cost_val)\n",
    "\n",
    "    \n",
    "training_epoch = 300 #(30번 반복한다는 뜻)\n",
    "batch_size = 100 # 55000개의 행을 다 읽어들이는게 아니라 100 개의 행을 읽어서 반복 학습.(100개씩 잘라서 55000개를 읽을거에요-2중루프 필요. 에폭포르푸, 배치포루프)\n",
    "\n",
    "for step in range(training_epoch):\n",
    "    num_of_iter = int(mnist.train.num_examples / batch_size )\n",
    "    cost_val = 0\n",
    "    for i in range(num_of_iter):\n",
    "        batch_x, batch_y =mnist.train.next_batch(batch_size)\n",
    "        _, cost_val = sess.run([train,cost],\n",
    "                              feed_dict={X:batch_x,Y:batch_y})\n",
    "    if step % 30 ==0:\n",
    "        print(cost_val)\n",
    "\n",
    "#Accuracy 측정\n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy =tf.reduce_mean(tf.cast(correct,dtype=tf.float32))\n",
    "\n",
    "result=sess.run(accuracy, feed_dict={X:mnist.test.images, Y:mnist.test.labels})\n",
    "print(\"정확도 : {}\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_data=pd.read_csv('./data/digit_recognizer/test.csv')\n",
    "\n",
    "predict = tf.argmax(H,1)\n",
    "result = sess.run(predict, feed_dict={X:test_x_data,keep_prob:1.0 })\n",
    "print(result)\n",
    "\n",
    "df_predict = pd.DataFrame({\n",
    "    'ImageId ': [i for i in range(1,len(test_x_data)+1)],\n",
    "    'Label': result\n",
    "})\n",
    "display(df_predict)\n",
    "\n",
    "df_predict.to_csv(\"./data/digit_recognizer/submission.csv\", mode='w', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpu_env] *",
   "language": "python",
   "name": "conda-env-cpu_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
